{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #大概需要2G的显存\n",
    "EPOCHS=5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((x, z), axis=1)\n",
    "    data2 = np.concatenate((z, z), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "\n",
    "def right_bottom(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((z, z), axis=1)\n",
    "    data2 = np.concatenate((z, x), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "def getType(dataset,x):\n",
    "        index = np.where(dataset[:, 0] == x)\n",
    "        for i in index:\n",
    "            Type = dataset[i]\n",
    "        return Type\n",
    "def getPixel(x):\n",
    "        pixel = x[:, 1:]\n",
    "        return pixel\n",
    "def getLabel(x):\n",
    "        label = x[:, 0]\n",
    "        return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = pd.read_csv('mnist_train.csv')\n",
    "mnist_test=pd.read_csv('mnist_test.csv')\n",
    "\n",
    "nrow = 28\n",
    "ncol = 28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_data(dataset):\n",
    "    \n",
    "    train = dataset.values\n",
    "    type0=getType(train,0)\n",
    "    type1=getType(train,1)\n",
    "\n",
    "    # X and label\n",
    "    x0 = getPixel(type0)\n",
    "    x1 =  getPixel(type1)\n",
    "    y0 = getLabel(type0)\n",
    "    y1 =  getLabel(type1)\n",
    "    y1=y1-1+1\n",
    "    y0=y0-y0\n",
    "    \n",
    "    # X reshape to 28 28\n",
    "    nx1 = x1.shape[0]\n",
    "    nx0 = x0.shape[0]\n",
    "    x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "    x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "\n",
    "    left0 = left_top(x0_reshape)\n",
    "    right1 = right_bottom(x1_reshape)\n",
    "    target = np.concatenate((left0, right1), axis=0)\n",
    "\n",
    "    target = torch.from_numpy(target)\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    label = np.concatenate((y0, y1), axis=0)\n",
    "\n",
    "    label=torch.from_numpy(label)\n",
    "    return target,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtr,ytr=train_data(mnist_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        self.len = ytr.shape[0]\n",
    "        self.x_data = xtr\n",
    "        self.y_data = ytr\n",
    "        # self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "#         if self.transform:\n",
    "#             x = self.transform(x)\n",
    "        #img = Image.fromarray(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "trainset= train()\n",
    "train_loader = DataLoader(dataset=trainset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(dataset):\n",
    "    \n",
    "    test = dataset.values\n",
    "    type0=getType(test,0)\n",
    "    type1=getType(test,1)\n",
    "    \n",
    "    # X and label\n",
    "    x0 = getPixel(type0)\n",
    "    x1 =  getPixel(type1)\n",
    "    y0 = getLabel(type0)\n",
    "    y1 =  getLabel(type1)\n",
    "    y1=y1-1+1\n",
    "    y0=y0-y0\n",
    "    \n",
    "    # X reshape to 28 28\n",
    "    nx1 = x1.shape[0]\n",
    "    nx0 = x0.shape[0]\n",
    "    x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "    x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "\n",
    "    left0 = left_top(x0_reshape)\n",
    "    right1 = right_bottom(x1_reshape)\n",
    "    target = np.concatenate((left0, right1), axis=0)\n",
    "\n",
    "    target = torch.from_numpy(target)\n",
    "    target = torch.unsqueeze(target, 1)\n",
    "    label = np.concatenate((y0, y1), axis=0)\n",
    "\n",
    "    label=torch.from_numpy(label)\n",
    "    return target,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "xts,yts=test_data(mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(Dataset):\n",
    "    def __init__(self):\n",
    "  \n",
    "     \n",
    "        self.len = yts.shape[0]\n",
    "\n",
    "        self.x_data = xts\n",
    "\n",
    "        self.y_data = yts\n",
    "        \n",
    "        # self.transform = transform\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # img = Image.fromarray(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "testset = test()\n",
    "test_loader = DataLoader(dataset=testset,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(2880,300)\n",
    "        self.fc2 = nn.Linear(300,2)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = F.relu(out)   \n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = F.log_softmax(out,dim=1)\n",
    "        # out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(DEVICE)\n",
    "model= model.double()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # print(data.size(), target.size())\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        # print(output)\n",
    "        #print(target)\n",
    "        # loss = F.nll_loss(output, target)\n",
    "        # print(loss)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%50 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.double())\n",
    "#             print(output)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [1568/12665 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [3168/12665 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [4768/12665 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6368/12665 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [7968/12665 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9568/12665 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [11168/12665 (88%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 2115/2115 (100.0000%)\n",
      "\n",
      "Train Epoch: 2 [1568/12665 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [3168/12665 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [4768/12665 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [6368/12665 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [7968/12665 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [9568/12665 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [11168/12665 (88%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 2115/2115 (100.0000%)\n",
      "\n",
      "Train Epoch: 3 [1568/12665 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [3168/12665 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [4768/12665 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [6368/12665 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [7968/12665 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [9568/12665 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [11168/12665 (88%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 2115/2115 (100.0000%)\n",
      "\n",
      "Train Epoch: 4 [1568/12665 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [3168/12665 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [4768/12665 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [6368/12665 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [7968/12665 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [9568/12665 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [11168/12665 (88%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 2115/2115 (100.0000%)\n",
      "\n",
      "Train Epoch: 5 [1568/12665 (12%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [3168/12665 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [4768/12665 (38%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [6368/12665 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [7968/12665 (63%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [9568/12665 (76%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [11168/12665 (88%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0000, Accuracy: 2115/2115 (100.0000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
