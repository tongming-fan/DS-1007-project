{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #大概需要2G的显存\n",
    "EPOCHS=5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "mnist_train = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((x, z), axis=1)\n",
    "    data2 = np.concatenate((z, z), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "def right_bottom(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((z, z), axis=1)\n",
    "    data2 = np.concatenate((z, x), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getType(dataset,x):\n",
    "    index = np.where(dataset[:, 0] == x)\n",
    "    for i in index:\n",
    "        Type = dataset[i]\n",
    "    return Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPixel(x):\n",
    "    pixel = x[:, 1:]\n",
    "    return pixel\n",
    "def getLabel(x):\n",
    "    label = x[:, 0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist_train.values\n",
    "\n",
    "mnist_train_0=getType(train,0)\n",
    "mnist_train_1=getType(train,1)   \n",
    "mnist_train_2=getType(train,2)\n",
    "mnist_train_3=getType(train,3)  \n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(mnist_train_1)\n",
    "x0 =getPixel(mnist_train_0)\n",
    "y1 = getLabel(mnist_train_1)\n",
    "y0 = getLabel(mnist_train_0)\n",
    "x2 = getPixel(mnist_train_2)\n",
    "x3 =getPixel(mnist_train_3)\n",
    "y2= getLabel(mnist_train_2)\n",
    "y3 = getLabel(mnist_train_3)\n",
    "\n",
    "# X reshape to 28 28\n",
    "\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "#------------------------------------------\n",
    "left0 = left_top(x0_reshape)\n",
    "right1 = right_bottom(x1_reshape) \n",
    "left2=left_top(x2_reshape)\n",
    "right3=right_bottom(x3_reshape)\n",
    "#------------------------------------------\n",
    "\n",
    "train_data1 = np.concatenate((left0, right1), axis=0)\n",
    "train_data2 = np.concatenate((left2, right3), axis=0)\n",
    "train_data= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "\n",
    "# reshape to 3136 which is 56*56\n",
    "train_data_reshape = train_data\n",
    "train_data_reshape = torch.from_numpy(train_data_reshape)\n",
    "xtr = torch.unsqueeze(train_data_reshape, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yy=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "ytr=torch.from_numpy(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt_digit(xtr[1,:])\n",
    "plt.subplot(1,4,2)\n",
    "plt_digit(xtr[10000,:])\n",
    "plt.subplot(1,4,3)\n",
    "plt_digit(xtr[15000,:])\n",
    "plt.subplot(1,4,4)\n",
    "plt_digit(xtr[20000,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = ytr.shape[0]\n",
    "        self.x_data = xtr\n",
    "        self.y_data = ytr\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset1= train()\n",
    "train_loader = DataLoader(dataset=dataset1,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = pd.read_csv('mnist_test.csv')\n",
    "testtest= mnist_test.values\n",
    "\n",
    "\n",
    "test0=getType(testtest,0)\n",
    "test1=getType(testtest,1)\n",
    "test2=getType(testtest,2)\n",
    "test3=getType(testtest,3)\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(test1)\n",
    "x0 =getPixel(test0)\n",
    "y1 = getLabel(test1)\n",
    "y0 = getLabel(test0)\n",
    "x2 = getPixel(test2)\n",
    "x3 =getPixel(test3)\n",
    "y2 = getLabel(test2)\n",
    "y3 = getLabel(test3)\n",
    "\n",
    "\n",
    "\n",
    "# X reshape to 28 28\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "\n",
    "#------------------------------------------\n",
    "right0 = right_bottom(x0_reshape)\n",
    "left1 = left_top(x1_reshape)\n",
    "left2=left_top(x2_reshape)\n",
    "right3=right_bottom(x3_reshape)\n",
    "#------------------------------------------        \n",
    "\n",
    "\n",
    "train_data1 = np.concatenate((right0, left1), axis=0)\n",
    "train_data2 = np.concatenate((left2, right3), axis=0)\n",
    "xts= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "\n",
    "xts = torch.from_numpy(xts)\n",
    "xts = torch.unsqueeze(xts, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yts=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "\n",
    "yts=torch.from_numpy(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt_digit(xts[1,:])\n",
    "plt.subplot(1,4,2)\n",
    "plt_digit(xts[1000,:])\n",
    "plt.subplot(1,4,3)\n",
    "plt_digit(xts[3000,:])\n",
    "plt.subplot(1,4,4)\n",
    "plt_digit(xts[4000,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = yts.shape[0]\n",
    "\n",
    "        self.x_data = xts\n",
    "\n",
    "        self.y_data = yts\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # img = Image.fromarray(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset2 = test()\n",
    "test_loader = DataLoader(dataset=dataset2,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(2880,300)\n",
    "        self.fc2 = nn.Linear(300,4)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = F.relu(out)   \n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = F.log_softmax(out,dim=1)\n",
    "        # out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(DEVICE)\n",
    "model= model.double()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # print(data.size(), target.size())\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        # print(output)\n",
    "        #print(target)\n",
    "        # loss = F.nll_loss(output, target)\n",
    "        # print(loss)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.double())\n",
    "#             print(target)\n",
    "#             print(output)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3168/24754 (13%)]\tLoss: 0.062069\n",
      "Train Epoch: 1 [6368/24754 (26%)]\tLoss: 0.001709\n",
      "Train Epoch: 1 [9568/24754 (39%)]\tLoss: 0.000194\n",
      "Train Epoch: 1 [12768/24754 (52%)]\tLoss: 0.000052\n",
      "Train Epoch: 1 [15968/24754 (64%)]\tLoss: 0.000277\n",
      "Train Epoch: 1 [19168/24754 (77%)]\tLoss: 0.001533\n",
      "Train Epoch: 1 [22368/24754 (90%)]\tLoss: 0.000394\n",
      "\n",
      "Test set: Average loss: 10.1977, Accuracy: 2021/4157 (48.6168%)\n",
      "\n",
      "Train Epoch: 2 [3168/24754 (13%)]\tLoss: 0.000044\n",
      "Train Epoch: 2 [6368/24754 (26%)]\tLoss: 0.007269\n",
      "Train Epoch: 2 [9568/24754 (39%)]\tLoss: 0.002299\n",
      "Train Epoch: 2 [12768/24754 (52%)]\tLoss: 0.000030\n",
      "Train Epoch: 2 [15968/24754 (64%)]\tLoss: 0.052610\n",
      "Train Epoch: 2 [19168/24754 (77%)]\tLoss: 0.000966\n",
      "Train Epoch: 2 [22368/24754 (90%)]\tLoss: 0.024813\n",
      "\n",
      "Test set: Average loss: 10.1455, Accuracy: 2033/4157 (48.9055%)\n",
      "\n",
      "Train Epoch: 3 [3168/24754 (13%)]\tLoss: 0.000221\n",
      "Train Epoch: 3 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [9568/24754 (39%)]\tLoss: 0.000629\n",
      "Train Epoch: 3 [12768/24754 (52%)]\tLoss: 0.000001\n",
      "Train Epoch: 3 [15968/24754 (64%)]\tLoss: 0.061254\n",
      "Train Epoch: 3 [19168/24754 (77%)]\tLoss: 0.000008\n",
      "Train Epoch: 3 [22368/24754 (90%)]\tLoss: 0.000162\n",
      "\n",
      "Test set: Average loss: 8.1791, Accuracy: 2033/4157 (48.9055%)\n",
      "\n",
      "Train Epoch: 4 [3168/24754 (13%)]\tLoss: 0.000023\n",
      "Train Epoch: 4 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [9568/24754 (39%)]\tLoss: 0.000010\n",
      "Train Epoch: 4 [12768/24754 (52%)]\tLoss: 0.000010\n",
      "Train Epoch: 4 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [22368/24754 (90%)]\tLoss: 0.002110\n",
      "\n",
      "Test set: Average loss: 10.4009, Accuracy: 2039/4157 (49.0498%)\n",
      "\n",
      "Train Epoch: 5 [3168/24754 (13%)]\tLoss: 0.000036\n",
      "Train Epoch: 5 [6368/24754 (26%)]\tLoss: 0.001619\n",
      "Train Epoch: 5 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [12768/24754 (52%)]\tLoss: 0.005333\n",
      "Train Epoch: 5 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [19168/24754 (77%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [22368/24754 (90%)]\tLoss: 0.000084\n",
      "\n",
      "Test set: Average loss: 12.2373, Accuracy: 2041/4157 (49.0979%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
