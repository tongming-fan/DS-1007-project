{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #大概需要2G的显存\n",
    "EPOCHS=5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "train_dataset = pd.read_csv('mnist_train.csv')\n",
    "test_dataset= pd.read_csv('mnist_test.csv')\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "\n",
    "# from itertools import combinations\n",
    "# l =range(10)\n",
    "# combination=list(combinations(l, 2))\n",
    "# # print (list(combinations(l, 2)))\n",
    "# (a,b)=combination[0]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((x, z), axis=1)\n",
    "    data2 = np.concatenate((z, z), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "def right_bottom(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((z, z), axis=1)\n",
    "    data2 = np.concatenate((z, x), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "\n",
    "def getType(dataset,x):\n",
    "    index = np.where(dataset[:, 0] == x)\n",
    "    for i in index:\n",
    "        Type = dataset[i]\n",
    "    return Type\n",
    "\n",
    "def getPixel(x):\n",
    "    pixel = x[:, 1:]\n",
    "    return pixel\n",
    "def getLabel(x):\n",
    "    label = x[:, 0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def traindata(dataset,i,j):\n",
    "    dataset=dataset.values\n",
    "#number i and j set\n",
    "    type1=getType(dataset,i)\n",
    "    type2=getType(dataset,j)\n",
    "# data and label of the two sets\n",
    "    x0 = type1[:, 1:]\n",
    "    x1 = type2[:, 1:]\n",
    "    y0 = type1[:, 0]\n",
    "    y1 = type2[:, 0]\n",
    "#label norm to adjust the pytorch cnn model\n",
    "    y0=y0-i\n",
    "    y1=y1-j+1\n",
    "#  reshape X to 28*28\n",
    "    nx1 = x1.shape[0]\n",
    "    nx0 = x0.shape[0]\n",
    "    x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "    x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "#Image transform------------------------\n",
    "    left0 = left_top(x0_reshape)\n",
    "    right1 = right_bottom(x1_reshape)\n",
    "#concatenate the two type data-------------\n",
    "    target = np.concatenate((left0, right1), axis=0)\n",
    "    target= torch.from_numpy(target)\n",
    "    target=torch.unsqueeze(target, 1)\n",
    "    label = np.concatenate((y0, y1), axis=0)\n",
    "    label=torch.from_numpy(label)\n",
    "    return target,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testdata(dataset,i,j):\n",
    "    dataset=dataset.values\n",
    "#number i and j set\n",
    "    type1=getType(dataset,i)\n",
    "    type2=getType(dataset,j)\n",
    "# data and label of the two sets\n",
    "    x0 = type1[:, 1:]\n",
    "    x1 = type2[:, 1:]\n",
    "    y0 = type1[:, 0]\n",
    "    y1 = type2[:, 0]\n",
    "#label norm to adjust the pytorch cnn model\n",
    "    y0=y0-i\n",
    "    y1=y1-j+1\n",
    "#  reshape X to 28*28\n",
    "    nx1 = x1.shape[0]\n",
    "    nx0 = x0.shape[0]\n",
    "    x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "    x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "#Image transform------------------------\n",
    "    right0 = right_bottom(x0_reshape)\n",
    "    left1 = left_top(x1_reshape)\n",
    "#concatenate the two type data-------------\n",
    "    target = np.concatenate((right0, left1), axis=0)\n",
    "    target= torch.from_numpy(target)\n",
    "    target=torch.unsqueeze(target, 1)\n",
    "    label = np.concatenate((y0, y1), axis=0)\n",
    "    label=torch.from_numpy(label)\n",
    "    return target,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_target,train_label)=traindata(train_dataset,1,9)\n",
    "(test_target,test_label)=testdata(train_dataset,1,9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(Dataset):\n",
    "    def __init__(self):\n",
    "#         x=train_target\n",
    "#         y=train_label\n",
    "        y=train_label\n",
    "        self.len = y.shape[0]\n",
    "        self.x = train_target\n",
    "        self.y =train_label\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset1= train()\n",
    "train_loader = DataLoader(dataset=dataset1,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(Dataset):\n",
    "    def __init__(self):\n",
    "#         x=train_target\n",
    "#         y=train_label\n",
    "        y=test_label\n",
    "        self.len = y.shape[0]\n",
    "        self.x = test_target\n",
    "        self.y =test_label\n",
    "    def __getitem__(self, index):\n",
    "        return self.x[index], self.y[index]\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset2 = test()\n",
    "test_loader = DataLoader(dataset=dataset2,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(2880,300)\n",
    "        self.fc2 = nn.Linear(300,2)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = F.relu(out)   \n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(DEVICE)\n",
    "model= model.double()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "     \n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.double())\n",
    "            \n",
    "#             print(output)\n",
    "#             print(target)\n",
    "            \n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3168/12691 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [6368/12691 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 1 [9568/12691 (75%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 217.4413, Accuracy: 0/12691 (0.0000%)\n",
      "\n",
      "Train Epoch: 2 [3168/12691 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [6368/12691 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 2 [9568/12691 (75%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 217.4413, Accuracy: 0/12691 (0.0000%)\n",
      "\n",
      "Train Epoch: 3 [3168/12691 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [6368/12691 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 3 [9568/12691 (75%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 217.4413, Accuracy: 0/12691 (0.0000%)\n",
      "\n",
      "Train Epoch: 4 [3168/12691 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [6368/12691 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [9568/12691 (75%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 217.4413, Accuracy: 0/12691 (0.0000%)\n",
      "\n",
      "Train Epoch: 5 [3168/12691 (25%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [6368/12691 (50%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [9568/12691 (75%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 217.4413, Accuracy: 0/12691 (0.0000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
