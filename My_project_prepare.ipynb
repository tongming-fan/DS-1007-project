{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #大概需要2G的显存\n",
    "EPOCHS=5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "mnist_train = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((x, z), axis=1)\n",
    "    data2 = np.concatenate((z, z), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "def right_bottom(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((z, z), axis=1)\n",
    "    data2 = np.concatenate((z, x), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getType(dataset,x):\n",
    "    index = np.where(dataset[:, 0] == x)\n",
    "    for i in index:\n",
    "        Type = dataset[i]\n",
    "    return Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPixel(x):\n",
    "    pixel = x[:, 1:]\n",
    "    return pixel\n",
    "def getLabel(x):\n",
    "    label = x[:, 0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist_train.values\n",
    "\n",
    "mnist_train_0=getType(train,0)\n",
    "mnist_train_1=getType(train,1)   \n",
    "mnist_train_2=getType(train,2)\n",
    "mnist_train_3=getType(train,3)  \n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(mnist_train_1)\n",
    "x0 =getPixel(mnist_train_0)\n",
    "y1 = getLabel(mnist_train_1)\n",
    "y0 = getLabel(mnist_train_0)\n",
    "x2 = getPixel(mnist_train_2)\n",
    "x3 =getPixel(mnist_train_3)\n",
    "y2= getLabel(mnist_train_2)\n",
    "y3 = getLabel(mnist_train_3)\n",
    "\n",
    "# X reshape to 28 28\n",
    "\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "#------------------------------------------\n",
    "left0 = left_top(x0_reshape)\n",
    "right1 = right_bottom(x1_reshape) \n",
    "left2=left_top(x2_reshape)\n",
    "right3=right_bottom(x3_reshape)\n",
    "#------------------------------------------\n",
    "\n",
    "train_data1 = np.concatenate((left0, right1), axis=0)\n",
    "train_data2 = np.concatenate((left2, right3), axis=0)\n",
    "train_data= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "\n",
    "# reshape to 3136 which is 56*56\n",
    "train_data_reshape = train_data\n",
    "train_data_reshape = torch.from_numpy(train_data_reshape)\n",
    "xtr = torch.unsqueeze(train_data_reshape, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yy=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "ytr=torch.from_numpy(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt_digit(xtr[1,:])\n",
    "plt.subplot(1,4,2)\n",
    "plt_digit(xtr[10000,:])\n",
    "plt.subplot(1,4,3)\n",
    "plt_digit(xtr[15000,:])\n",
    "plt.subplot(1,4,4)\n",
    "plt_digit(xtr[20000,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = ytr.shape[0]\n",
    "        self.x_data = xtr\n",
    "        self.y_data = ytr\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset1= train()\n",
    "train_loader = DataLoader(dataset=dataset1,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = pd.read_csv('mnist_test.csv')\n",
    "testtest= mnist_test.values\n",
    "\n",
    "\n",
    "test0=getType(testtest,0)\n",
    "test1=getType(testtest,1)\n",
    "test2=getType(testtest,2)\n",
    "test3=getType(testtest,3)\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(test1)\n",
    "x0 =getPixel(test0)\n",
    "y1 = getLabel(test1)\n",
    "y0 = getLabel(test0)\n",
    "x2 = getPixel(test2)\n",
    "x3 =getPixel(test3)\n",
    "y2 = getLabel(test2)\n",
    "y3 = getLabel(test3)\n",
    "\n",
    "\n",
    "\n",
    "# X reshape to 28 28\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "\n",
    "#------------------------------------------\n",
    "right0 = right_bottom(x0_reshape)\n",
    "left1= left_top(x1_reshape) \n",
    "right2=right_bottom(x2_reshape)\n",
    "left3=left_top(x3_reshape)\n",
    "#------------------------------------------        \n",
    "\n",
    "\n",
    "train_data1 = np.concatenate((right0, left1), axis=0)\n",
    "train_data2 = np.concatenate((right2, left3), axis=0)\n",
    "xts= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "\n",
    "xts = torch.from_numpy(xts)\n",
    "xts = torch.unsqueeze(xts, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yts=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "\n",
    "yts=torch.from_numpy(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "plt_digit(xts[1,:])\n",
    "plt.subplot(2,4,2)\n",
    "plt_digit(xts[1000,:])\n",
    "plt.subplot(2,4,3)\n",
    "plt_digit(xts[3000,:])\n",
    "plt.subplot(2,4,4)\n",
    "plt_digit(xts[4000,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = yts.shape[0]\n",
    "\n",
    "        self.x_data = xts\n",
    "\n",
    "        self.y_data = yts\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # img = Image.fromarray(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset2 = test()\n",
    "test_loader = DataLoader(dataset=dataset2,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(2880,300)\n",
    "        self.fc2 = nn.Linear(300,4)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = F.relu(out)   \n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = F.log_softmax(out,dim=1)\n",
    "        # out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(DEVICE)\n",
    "model= model.double()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # print(data.size(), target.size())\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        # print(output)\n",
    "        #print(target)\n",
    "        # loss = F.nll_loss(output, target)\n",
    "        # print(loss)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.double())\n",
    "#             print(target)\n",
    "#             print(output)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3168/24754 (13%)]\tLoss: 0.019074\n",
      "Train Epoch: 1 [6368/24754 (26%)]\tLoss: 0.000534\n",
      "Train Epoch: 1 [9568/24754 (39%)]\tLoss: 0.073731\n",
      "Train Epoch: 1 [12768/24754 (52%)]\tLoss: 0.035113\n",
      "Train Epoch: 1 [15968/24754 (64%)]\tLoss: 0.007293\n",
      "Train Epoch: 1 [19168/24754 (77%)]\tLoss: 0.000374\n",
      "Train Epoch: 1 [22368/24754 (90%)]\tLoss: 0.070072\n",
      "\n",
      "Test set: Average loss: 13.0317, Accuracy: 0/4157 (0.0000%)\n",
      "\n",
      "Train Epoch: 2 [3168/24754 (13%)]\tLoss: 0.000209\n",
      "Train Epoch: 2 [6368/24754 (26%)]\tLoss: 0.002025\n",
      "Train Epoch: 2 [9568/24754 (39%)]\tLoss: 0.001954\n",
      "Train Epoch: 2 [12768/24754 (52%)]\tLoss: 0.000885\n",
      "Train Epoch: 2 [15968/24754 (64%)]\tLoss: 0.000788\n",
      "Train Epoch: 2 [19168/24754 (77%)]\tLoss: 0.001066\n",
      "Train Epoch: 2 [22368/24754 (90%)]\tLoss: 0.000002\n",
      "\n",
      "Test set: Average loss: 16.0292, Accuracy: 0/4157 (0.0000%)\n",
      "\n",
      "Train Epoch: 3 [3168/24754 (13%)]\tLoss: 0.001353\n",
      "Train Epoch: 3 [6368/24754 (26%)]\tLoss: 0.004324\n",
      "Train Epoch: 3 [9568/24754 (39%)]\tLoss: 0.000110\n",
      "Train Epoch: 3 [12768/24754 (52%)]\tLoss: 0.000002\n",
      "Train Epoch: 3 [15968/24754 (64%)]\tLoss: 0.010315\n",
      "Train Epoch: 3 [19168/24754 (77%)]\tLoss: 0.011762\n",
      "Train Epoch: 3 [22368/24754 (90%)]\tLoss: 0.002615\n",
      "\n",
      "Test set: Average loss: 15.6237, Accuracy: 0/4157 (0.0000%)\n",
      "\n",
      "Train Epoch: 4 [3168/24754 (13%)]\tLoss: 0.000050\n",
      "Train Epoch: 4 [6368/24754 (26%)]\tLoss: 0.001383\n",
      "Train Epoch: 4 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [12768/24754 (52%)]\tLoss: 0.000097\n",
      "Train Epoch: 4 [15968/24754 (64%)]\tLoss: 0.000077\n",
      "Train Epoch: 4 [19168/24754 (77%)]\tLoss: 0.000007\n",
      "Train Epoch: 4 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 22.9817, Accuracy: 0/4157 (0.0000%)\n",
      "\n",
      "Train Epoch: 5 [3168/24754 (13%)]\tLoss: 0.004374\n",
      "Train Epoch: 5 [6368/24754 (26%)]\tLoss: 0.000575\n",
      "Train Epoch: 5 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [12768/24754 (52%)]\tLoss: 0.000044\n",
      "Train Epoch: 5 [15968/24754 (64%)]\tLoss: 0.000010\n",
      "Train Epoch: 5 [19168/24754 (77%)]\tLoss: 0.000004\n",
      "Train Epoch: 5 [22368/24754 (90%)]\tLoss: 0.001947\n",
      "\n",
      "Test set: Average loss: 27.6355, Accuracy: 0/4157 (0.0000%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
