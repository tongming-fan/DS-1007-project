{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #大概需要2G的显存\n",
    "EPOCHS=20\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "mnist_train = pd.read_csv('mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((x, z), axis=1)\n",
    "    data2 = np.concatenate((z, z), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "def right_bottom(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((z, z), axis=1)\n",
    "    data2 = np.concatenate((z, x), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getType(dataset,x):\n",
    "    index = np.where(dataset[:, 0] == x)\n",
    "    for i in index:\n",
    "        Type = dataset[i]\n",
    "    return Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPixel(x):\n",
    "    pixel = x[:, 1:]\n",
    "    return pixel\n",
    "def getLabel(x):\n",
    "    label = x[:, 0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist_train.values\n",
    "\n",
    "mnist_train_0=getType(train,0)\n",
    "mnist_train_1=getType(train,1)   \n",
    "mnist_train_2=getType(train,2)\n",
    "mnist_train_3=getType(train,3)  \n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(mnist_train_1)\n",
    "x0 =getPixel(mnist_train_0)\n",
    "y1 = getLabel(mnist_train_1)\n",
    "y0 = getLabel(mnist_train_0)\n",
    "x2 = getPixel(mnist_train_2)\n",
    "x3 =getPixel(mnist_train_3)\n",
    "y2= getLabel(mnist_train_2)\n",
    "y3 = getLabel(mnist_train_3)\n",
    "\n",
    "# X reshape to 28 28\n",
    "\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "#------------------------------------------\n",
    "left0 = left_top(x0_reshape)\n",
    "right1 = right_bottom(x1_reshape) \n",
    "left2=left_top(x2_reshape)\n",
    "right3=right_bottom(x3_reshape)\n",
    "#------------------------------------------\n",
    "\n",
    "train_data1 = np.concatenate((left0, right1), axis=0)\n",
    "train_data2 = np.concatenate((left2, right3), axis=0)\n",
    "train_data= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "\n",
    "# reshape to 3136 which is 56*56\n",
    "train_data_reshape = train_data\n",
    "train_data_reshape = torch.from_numpy(train_data_reshape)\n",
    "xtr = torch.unsqueeze(train_data_reshape, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yy=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "ytr=torch.from_numpy(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt_digit(xtr[1,:])\n",
    "plt.subplot(1,4,2)\n",
    "plt_digit(xtr[10000,:])\n",
    "plt.subplot(1,4,3)\n",
    "plt_digit(xtr[15000,:])\n",
    "plt.subplot(1,4,4)\n",
    "plt_digit(xtr[20000,:])\n",
    "plt.title('train')\n",
    "plt.savefig('5.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = ytr.shape[0]\n",
    "        self.x_data = xtr\n",
    "        self.y_data = ytr\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset1= train()\n",
    "train_loader = DataLoader(dataset=dataset1,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = pd.read_csv('mnist_test.csv')\n",
    "testtest= mnist_test.values\n",
    "\n",
    "\n",
    "test0=getType(testtest,0)\n",
    "test1=getType(testtest,1)\n",
    "test2=getType(testtest,2)\n",
    "test3=getType(testtest,3)\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(test1)\n",
    "x0 =getPixel(test0)\n",
    "y1 = getLabel(test1)\n",
    "y0 = getLabel(test0)\n",
    "x2 = getPixel(test2)\n",
    "x3 =getPixel(test3)\n",
    "y2 = getLabel(test2)\n",
    "y3 = getLabel(test3)\n",
    "\n",
    "\n",
    "\n",
    "# X reshape to 28 28\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "\n",
    "#------------------------------------------\n",
    "left0 = left_top(x0_reshape)\n",
    "right1 = right_bottom(x1_reshape) \n",
    "left2=left_top(x2_reshape)\n",
    "right3=right_bottom(x3_reshape)\n",
    "#------------------------------------------        \n",
    "\n",
    "\n",
    "train_data1 = np.concatenate((left0, right1), axis=0)\n",
    "train_data2 = np.concatenate((left2, right3), axis=0)\n",
    "xts= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "\n",
    "xts = torch.from_numpy(xts)\n",
    "xts = torch.unsqueeze(xts, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yts=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "\n",
    "yts=torch.from_numpy(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "plt_digit(xts[1,:])\n",
    "plt.subplot(2,4,2)\n",
    "plt_digit(xts[1000,:])\n",
    "plt.subplot(2,4,3)\n",
    "plt_digit(xts[3000,:])\n",
    "plt.subplot(2,4,4)\n",
    "plt_digit(xts[4000,:])\n",
    "plt.title('test')\n",
    "plt.savefig('6.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = yts.shape[0]\n",
    "\n",
    "        self.x_data = xts\n",
    "\n",
    "        self.y_data = yts\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # img = Image.fromarray(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset2 = test()\n",
    "test_loader = DataLoader(dataset=dataset2,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(2880,300)\n",
    "        self.fc2 = nn.Linear(300,4)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = F.relu(out)   \n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = F.log_softmax(out,dim=1)\n",
    "        # out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(DEVICE)\n",
    "model= model.double()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # print(data.size(), target.size())\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        # print(output)\n",
    "        #print(target)\n",
    "        # loss = F.nll_loss(output, target)\n",
    "        # print(loss)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.double())\n",
    "#             print(target)\n",
    "#             print(output)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [3168/24754 (13%)]\tLoss: 0.005210\n",
      "Train Epoch: 1 [6368/24754 (26%)]\tLoss: 0.042106\n",
      "Train Epoch: 1 [9568/24754 (39%)]\tLoss: 0.000369\n",
      "Train Epoch: 1 [12768/24754 (52%)]\tLoss: 0.000503\n",
      "Train Epoch: 1 [15968/24754 (64%)]\tLoss: 0.000345\n",
      "Train Epoch: 1 [19168/24754 (77%)]\tLoss: 0.000875\n",
      "Train Epoch: 1 [22368/24754 (90%)]\tLoss: 0.000505\n",
      "\n",
      "Test set: Average loss: 0.0091, Accuracy: 4148/4157 (99.7835%)\n",
      "\n",
      "Train Epoch: 2 [3168/24754 (13%)]\tLoss: 0.000789\n",
      "Train Epoch: 2 [6368/24754 (26%)]\tLoss: 0.001349\n",
      "Train Epoch: 2 [9568/24754 (39%)]\tLoss: 0.095568\n",
      "Train Epoch: 2 [12768/24754 (52%)]\tLoss: 0.001089\n",
      "Train Epoch: 2 [15968/24754 (64%)]\tLoss: 0.000216\n",
      "Train Epoch: 2 [19168/24754 (77%)]\tLoss: 0.000486\n",
      "Train Epoch: 2 [22368/24754 (90%)]\tLoss: 0.000035\n",
      "\n",
      "Test set: Average loss: 0.0171, Accuracy: 4143/4157 (99.6632%)\n",
      "\n",
      "Train Epoch: 3 [3168/24754 (13%)]\tLoss: 0.000013\n",
      "Train Epoch: 3 [6368/24754 (26%)]\tLoss: 0.000002\n",
      "Train Epoch: 3 [9568/24754 (39%)]\tLoss: 0.000003\n",
      "Train Epoch: 3 [12768/24754 (52%)]\tLoss: 0.009781\n",
      "Train Epoch: 3 [15968/24754 (64%)]\tLoss: 0.000004\n",
      "Train Epoch: 3 [19168/24754 (77%)]\tLoss: 0.001756\n",
      "Train Epoch: 3 [22368/24754 (90%)]\tLoss: 0.001872\n",
      "\n",
      "Test set: Average loss: 0.0190, Accuracy: 4136/4157 (99.4948%)\n",
      "\n",
      "Train Epoch: 4 [3168/24754 (13%)]\tLoss: 0.000005\n",
      "Train Epoch: 4 [6368/24754 (26%)]\tLoss: 0.023446\n",
      "Train Epoch: 4 [9568/24754 (39%)]\tLoss: 0.014594\n",
      "Train Epoch: 4 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 4 [19168/24754 (77%)]\tLoss: 0.000006\n",
      "Train Epoch: 4 [22368/24754 (90%)]\tLoss: 0.000005\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 4151/4157 (99.8557%)\n",
      "\n",
      "Train Epoch: 5 [3168/24754 (13%)]\tLoss: 0.000207\n",
      "Train Epoch: 5 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 5 [9568/24754 (39%)]\tLoss: 0.000001\n",
      "Train Epoch: 5 [12768/24754 (52%)]\tLoss: 0.000358\n",
      "Train Epoch: 5 [15968/24754 (64%)]\tLoss: 0.000009\n",
      "Train Epoch: 5 [19168/24754 (77%)]\tLoss: 0.000084\n",
      "Train Epoch: 5 [22368/24754 (90%)]\tLoss: 0.000015\n",
      "\n",
      "Test set: Average loss: 0.0033, Accuracy: 4152/4157 (99.8797%)\n",
      "\n",
      "Train Epoch: 6 [3168/24754 (13%)]\tLoss: 0.026751\n",
      "Train Epoch: 6 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 6 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 6 [12768/24754 (52%)]\tLoss: 0.000002\n",
      "Train Epoch: 6 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 6 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 6 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0243, Accuracy: 4132/4157 (99.3986%)\n",
      "\n",
      "Train Epoch: 7 [3168/24754 (13%)]\tLoss: 0.000002\n",
      "Train Epoch: 7 [6368/24754 (26%)]\tLoss: 0.000050\n",
      "Train Epoch: 7 [9568/24754 (39%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 7 [15968/24754 (64%)]\tLoss: 0.000001\n",
      "Train Epoch: 7 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 7 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0018, Accuracy: 4153/4157 (99.9038%)\n",
      "\n",
      "Train Epoch: 8 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 8 [22368/24754 (90%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 4151/4157 (99.8557%)\n",
      "\n",
      "Train Epoch: 9 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [6368/24754 (26%)]\tLoss: 0.000177\n",
      "Train Epoch: 9 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [12768/24754 (52%)]\tLoss: 0.000046\n",
      "Train Epoch: 9 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 9 [22368/24754 (90%)]\tLoss: 0.000001\n",
      "\n",
      "Test set: Average loss: 0.0044, Accuracy: 4153/4157 (99.9038%)\n",
      "\n",
      "Train Epoch: 10 [3168/24754 (13%)]\tLoss: 0.000001\n",
      "Train Epoch: 10 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [9568/24754 (39%)]\tLoss: 0.000024\n",
      "Train Epoch: 10 [12768/24754 (52%)]\tLoss: 0.000020\n",
      "Train Epoch: 10 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 10 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0160, Accuracy: 4147/4157 (99.7594%)\n",
      "\n",
      "Train Epoch: 11 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [9568/24754 (39%)]\tLoss: 0.000003\n",
      "Train Epoch: 11 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 11 [15968/24754 (64%)]\tLoss: 0.000014\n",
      "Train Epoch: 11 [19168/24754 (77%)]\tLoss: 0.000001\n",
      "Train Epoch: 11 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0019, Accuracy: 4156/4157 (99.9759%)\n",
      "\n",
      "Train Epoch: 12 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 12 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 12 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 12 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 12 [15968/24754 (64%)]\tLoss: 0.001409\n",
      "Train Epoch: 12 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 12 [22368/24754 (90%)]\tLoss: 0.000004\n",
      "\n",
      "Test set: Average loss: 0.0075, Accuracy: 4151/4157 (99.8557%)\n",
      "\n",
      "Train Epoch: 13 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [6368/24754 (26%)]\tLoss: 0.000071\n",
      "Train Epoch: 13 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [12768/24754 (52%)]\tLoss: 0.000061\n",
      "Train Epoch: 13 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 13 [22368/24754 (90%)]\tLoss: 0.000009\n",
      "\n",
      "Test set: Average loss: 0.0056, Accuracy: 4152/4157 (99.8797%)\n",
      "\n",
      "Train Epoch: 14 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [12768/24754 (52%)]\tLoss: 0.000001\n",
      "Train Epoch: 14 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 14 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0100, Accuracy: 4150/4157 (99.8316%)\n",
      "\n",
      "Train Epoch: 15 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 15 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0052, Accuracy: 4153/4157 (99.9038%)\n",
      "\n",
      "Train Epoch: 16 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [12768/24754 (52%)]\tLoss: 0.000130\n",
      "Train Epoch: 16 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 16 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 4155/4157 (99.9519%)\n",
      "\n",
      "Train Epoch: 17 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 17 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0294, Accuracy: 4147/4157 (99.7594%)\n",
      "\n",
      "Train Epoch: 18 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [9568/24754 (39%)]\tLoss: 0.000017\n",
      "Train Epoch: 18 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 18 [22368/24754 (90%)]\tLoss: 0.000186\n",
      "\n",
      "Test set: Average loss: 0.0043, Accuracy: 4153/4157 (99.9038%)\n",
      "\n",
      "Train Epoch: 19 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 19 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 19 [9568/24754 (39%)]\tLoss: 0.000046\n",
      "Train Epoch: 19 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 19 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 19 [19168/24754 (77%)]\tLoss: 0.000000\n",
      "Train Epoch: 19 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0037, Accuracy: 4155/4157 (99.9519%)\n",
      "\n",
      "Train Epoch: 20 [3168/24754 (13%)]\tLoss: 0.000000\n",
      "Train Epoch: 20 [6368/24754 (26%)]\tLoss: 0.000000\n",
      "Train Epoch: 20 [9568/24754 (39%)]\tLoss: 0.000000\n",
      "Train Epoch: 20 [12768/24754 (52%)]\tLoss: 0.000000\n",
      "Train Epoch: 20 [15968/24754 (64%)]\tLoss: 0.000000\n",
      "Train Epoch: 20 [19168/24754 (77%)]\tLoss: 0.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 20 [22368/24754 (90%)]\tLoss: 0.000000\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 4155/4157 (99.9519%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
