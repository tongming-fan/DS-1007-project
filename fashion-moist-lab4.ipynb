{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "from torchvision import datasets, transforms\n",
    "# from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE=32 #大概需要2G的显存\n",
    "EPOCHS=5\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "mnist_train = pd.read_csv('fashion-mnist_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def left_top(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((x, z), axis=1)\n",
    "    data2 = np.concatenate((z, z), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3\n",
    "def right_bottom(x):\n",
    "    nsam = x.shape[0]\n",
    "    nrow = x.shape[1]\n",
    "    ncol = x.shape[2]\n",
    "    z = np.zeros((nsam, nrow, ncol), dtype=np.double)\n",
    "    data1 = np.concatenate((z, z), axis=1)\n",
    "    data2 = np.concatenate((z, x), axis=1)\n",
    "    data3 = np.concatenate((data1, data2), 2)\n",
    "    return data3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getType(dataset,x):\n",
    "    index = np.where(dataset[:, 0] == x)\n",
    "    for i in index:\n",
    "        Type = dataset[i]\n",
    "    return Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPixel(x):\n",
    "    pixel = x[:, 1:]\n",
    "    return pixel\n",
    "def getLabel(x):\n",
    "    label = x[:, 0]\n",
    "    return label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = mnist_train.values\n",
    "\n",
    "mnist_train_0=getType(train,0)\n",
    "mnist_train_1=getType(train,1)   \n",
    "mnist_train_2=getType(train,2)\n",
    "mnist_train_3=getType(train,3)  \n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(mnist_train_1)\n",
    "x0 =getPixel(mnist_train_0)\n",
    "y1 = getLabel(mnist_train_1)\n",
    "y0 = getLabel(mnist_train_0)\n",
    "x2 = getPixel(mnist_train_2)\n",
    "x3 =getPixel(mnist_train_3)\n",
    "y2= getLabel(mnist_train_2)\n",
    "y3 = getLabel(mnist_train_3)\n",
    "\n",
    "# X reshape to 28 28\n",
    "\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "#------------------------------------------\n",
    "left0 = left_top(x0_reshape)\n",
    "right1 = right_bottom(x1_reshape) \n",
    "left2=left_top(x2_reshape)\n",
    "right3=right_bottom(x3_reshape)\n",
    "#------------------------------------------\n",
    "\n",
    "train_data1 = np.concatenate((left0, right1), axis=0)\n",
    "train_data2 = np.concatenate((left2, right3), axis=0)\n",
    "train_data= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "\n",
    "# reshape to 3136 which is 56*56\n",
    "train_data_reshape = train_data\n",
    "train_data_reshape = torch.from_numpy(train_data_reshape)\n",
    "xtr = torch.unsqueeze(train_data_reshape, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yy=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "ytr=torch.from_numpy(yy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(1,4,1)\n",
    "plt_digit(xtr[1,:])\n",
    "plt.subplot(1,4,2)\n",
    "plt_digit(xtr[10000,:])\n",
    "plt.subplot(1,4,3)\n",
    "plt_digit(xtr[15000,:])\n",
    "plt.subplot(1,4,4)\n",
    "plt_digit(xtr[20000,:])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class train(Dataset):\n",
    "    def __init__(self):\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = ytr.shape[0]\n",
    "        self.x_data = xtr\n",
    "        self.y_data = ytr\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "      \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset1= train()\n",
    "train_loader = DataLoader(dataset=dataset1,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test = pd.read_csv('fashion-mnist_test.csv')\n",
    "testtest= mnist_test.values\n",
    "\n",
    "\n",
    "test0=getType(testtest,0)\n",
    "test1=getType(testtest,1)\n",
    "test2=getType(testtest,2)\n",
    "test3=getType(testtest,3)\n",
    "nrow = 28\n",
    "ncol = 28\n",
    "\n",
    "# X and label\n",
    "x1 = getPixel(test1)\n",
    "x0 =getPixel(test0)\n",
    "y1 = getLabel(test1)\n",
    "y0 = getLabel(test0)\n",
    "x2 = getPixel(test2)\n",
    "x3 =getPixel(test3)\n",
    "y2 = getLabel(test2)\n",
    "y3 = getLabel(test3)\n",
    "\n",
    "\n",
    "\n",
    "# X reshape to 28 28\n",
    "nx1 = x1.shape[0]\n",
    "nx0 = x0.shape[0]\n",
    "nx2 = x2.shape[0]\n",
    "nx3 = x3.shape[0]\n",
    "\n",
    "x0_reshape = x0.reshape((nx0, nrow, ncol))\n",
    "x1_reshape = x1.reshape((nx1, nrow, ncol))\n",
    "x2_reshape = x2.reshape((nx2, nrow, ncol))\n",
    "x3_reshape = x3.reshape((nx3, nrow, ncol))\n",
    "\n",
    "#------------------------------------------\n",
    "right0 = right_bottom(x0_reshape)\n",
    "left1= left_top(x1_reshape) \n",
    "right2=right_bottom(x2_reshape)\n",
    "left3=left_top(x3_reshape)\n",
    "#------------------------------------------        \n",
    "\n",
    "\n",
    "train_data1 = np.concatenate((right0, left1), axis=0)\n",
    "train_data2 = np.concatenate((right2, left3), axis=0)\n",
    "xts= np.concatenate((train_data1, train_data2), axis=0)\n",
    "\n",
    "#------------------------------------------\n",
    "\n",
    "\n",
    "xts = torch.from_numpy(xts)\n",
    "xts = torch.unsqueeze(xts, 1)\n",
    "\n",
    "yy1 = np.concatenate((y0, y1), axis=0)\n",
    "yy2=np.concatenate((y2, y3), axis=0)\n",
    "yts=np.concatenate((yy1, yy2), axis=0)\n",
    "\n",
    "\n",
    "yts=torch.from_numpy(yts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 4000 is out of bounds for dimension 0 with size 4000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-01fe494c18e4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mplt_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m \u001b[0mplt_digit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 4000 is out of bounds for dimension 0 with size 4000"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 4 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "def plt_digit(x):\n",
    "    nrow = 56\n",
    "    ncol = 56\n",
    "    xsq = x.reshape((nrow,ncol))\n",
    "    plt.imshow(xsq,  cmap='Greys_r')\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "\n",
    "plt.subplot(2,4,1)\n",
    "plt_digit(xts[1,:])\n",
    "plt.subplot(2,4,2)\n",
    "plt_digit(xts[1000,:])\n",
    "plt.subplot(2,4,3)\n",
    "plt_digit(xts[3000,:])\n",
    "plt.subplot(2,4,4)\n",
    "plt_digit(xts[4000,:])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test(Dataset):\n",
    "    def __init__(self):\n",
    "\n",
    "        \n",
    "        \n",
    "      \n",
    "        self.len = yts.shape[0]\n",
    "\n",
    "        self.x_data = xts\n",
    "\n",
    "        self.y_data = yts\n",
    "\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # img = Image.fromarray(self.x_data[index])\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "dataset2 = test()\n",
    "test_loader = DataLoader(dataset=dataset2,\n",
    "                          batch_size=32,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 1,28x28\n",
    "        self.conv1=nn.Conv2d(1,10,5) # 10, 24x24\n",
    "        self.conv2=nn.Conv2d(10,20,3) # 128, 10x10\n",
    "        self.fc1 = nn.Linear(2880,300)\n",
    "        self.fc2 = nn.Linear(300,4)\n",
    "    def forward(self,x):\n",
    "        in_size = x.size(0)\n",
    "        out = self.conv1(x) #24\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = self.conv2(out) #10\n",
    "        out = F.relu(out)\n",
    "        out = F.max_pool2d(out, 2, 2)  #12\n",
    "        out = F.relu(out)   \n",
    "        out = out.view(in_size,-1)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        # out = F.log_softmax(out,dim=1)\n",
    "        # out = F.softmax(out,dim=1)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "model = model.to(DEVICE)\n",
    "model= model.double()\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "# criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        # print(data.size(), target.size())\n",
    "        optimizer.zero_grad()\n",
    "        output=model(data)\n",
    "        # print(output)\n",
    "        #print(target)\n",
    "        # loss = F.nll_loss(output, target)\n",
    "        # print(loss)\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "\n",
    "def test(model, device, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data.double())\n",
    "#             print(target)\n",
    "#             print(output)\n",
    "            test_loss += F.cross_entropy(output, target, reduction='sum').item() # 将一批的损失相加\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    \n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.4f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, DEVICE, train_loader, optimizer, epoch)\n",
    "    test(model, DEVICE, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
